{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Style Transfer\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Our Changes:\n",
    "\n",
    "Added code for saving the input content and style images. Also added code for saving the output mixed image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "Image('images/15_style_transfer_flowchart.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xu2SVpFJjmJr"
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import PIL.Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This was developed using Python 3.5.2 (Anaconda) and TensorFlow version:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import vgg16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The VGG-16 model is downloaded from the internet. This is the default directory where you want to save the data-files. The directory will be created if it does not exist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# vgg16.data_dir = 'vgg16/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vgg16.maybe_download()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Nv2JqNLBhy1j"
   },
   "source": [
    "## Helper-functions for image manipulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function loads an image and returns it as a numpy array of floating-points. The image can be automatically resized so the largest of the height or width equals `max_size`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_image(filename, max_size=None):\n",
    "    image = PIL.Image.open(filename)\n",
    "\n",
    "    if max_size is not None:\n",
    "        # Calculate the appropriate rescale-factor for\n",
    "        # ensuring a max height and width, while keeping\n",
    "        # the proportion between them.\n",
    "        factor = max_size / np.max(image.size)\n",
    "    \n",
    "        # Scale the image's height and width.\n",
    "        size = np.array(image.size) * factor\n",
    "\n",
    "        # The size is now floating-point because it was scaled.\n",
    "        # But PIL requires the size to be integers.\n",
    "        size = size.astype(int)\n",
    "\n",
    "        # Resize the image.\n",
    "        image = image.resize(size, PIL.Image.LANCZOS)\n",
    "        print(image)\n",
    "\n",
    "    # Convert to numpy floating-point array.\n",
    "    return np.float32(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save an image as a jpeg-file. The image is given as a numpy array with pixel-values between 0 and 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_image(image, filename):\n",
    "    # Ensure the pixel-values are between 0 and 255.\n",
    "    image = np.clip(image, 0.0, 255.0)\n",
    "    \n",
    "    # Convert to bytes.\n",
    "    image = image.astype(np.uint8)\n",
    "    \n",
    "    # Write the image-file in jpeg-format.\n",
    "    with open(filename, 'wb') as file:\n",
    "        PIL.Image.fromarray(image).save(file, 'jpeg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function plots a large image. The image is given as a numpy array with pixel-values between 0 and 255."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function plots the content-, mixed- and style-images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_image_big(image):\n",
    "    # Ensure the pixel-values are between 0 and 255.\n",
    "    image = np.clip(image, 0.0, 255.0)\n",
    "\n",
    "    # Convert pixels to bytes.\n",
    "    image = image.astype(np.uint8)\n",
    "\n",
    "    # Convert to a PIL-image and display it.\n",
    "    display(PIL.Image.fromarray(image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_images(content_image, style_image, mixed_image):\n",
    "    # Create figure with sub-plots.\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(10, 10))\n",
    "\n",
    "    # Adjust vertical spacing.\n",
    "    fig.subplots_adjust(hspace=0.1, wspace=0.1)\n",
    "\n",
    "    # Use interpolation to smooth pixels?\n",
    "    smooth = True\n",
    "    \n",
    "    # Interpolation type.\n",
    "    if smooth:\n",
    "        interpolation = 'sinc'\n",
    "    else:\n",
    "        interpolation = 'nearest'\n",
    "\n",
    "    # Plot the content-image.\n",
    "    # Note that the pixel-values are normalized to\n",
    "    # the [0.0, 1.0] range by dividing with 255.\n",
    "    ax = axes.flat[0]\n",
    "    ax.imshow(content_image / 255.0, interpolation=interpolation)\n",
    "    ax.set_xlabel(\"Content\")\n",
    "\n",
    "    # Plot the mixed-image.\n",
    "    ax = axes.flat[1]\n",
    "    ax.imshow(mixed_image / 255.0, interpolation=interpolation)\n",
    "    ax.set_xlabel(\"Mixed\")\n",
    "\n",
    "    # Plot the style-image\n",
    "    ax = axes.flat[2]\n",
    "    ax.imshow(style_image / 255.0, interpolation=interpolation)\n",
    "    ax.set_xlabel(\"Style\")\n",
    "\n",
    "    # Remove ticks from all the plots.\n",
    "    for ax in axes.flat:\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "    \n",
    "    # Ensure the plot is shown correctly with multiple plots\n",
    "    # in a single Notebook cell.\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss Functions\n",
    "\n",
    "These helper-functions create the loss-functions that are used in optimization with TensorFlow.\n",
    "\n",
    "This function creates a TensorFlow operation for calculating the Mean Squared Error between the two input tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mean_squared_error(a, b):\n",
    "    return tf.reduce_mean(tf.square(a - b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_content_loss(session, model, content_image, layer_ids):\n",
    "    \"\"\"\n",
    "    Create the loss-function for the content-image.\n",
    "    \n",
    "    Parameters:\n",
    "    session: An open TensorFlow session for running the model's graph.\n",
    "    model: The model, e.g. an instance of the VGG16-class.\n",
    "    content_image: Numpy float array with the content-image.\n",
    "    layer_ids: List of integer id's for the layers to use in the model.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create a feed-dict with the content-image.\n",
    "    feed_dict = model.create_feed_dict(image=content_image)\n",
    "\n",
    "    # Get references to the tensors for the given layers.\n",
    "    layers = model.get_layer_tensors(layer_ids)\n",
    "\n",
    "    # Calculate the output values of those layers when\n",
    "    # feeding the content-image to the model.\n",
    "    values = session.run(layers, feed_dict=feed_dict)\n",
    "\n",
    "    # Set the model's graph as the default so we can add\n",
    "    # computational nodes to it. It is not always clear\n",
    "    # when this is necessary in TensorFlow, but if you\n",
    "    # want to re-use this code then it may be necessary.\n",
    "    with model.graph.as_default():\n",
    "        # Initialize an empty list of loss-functions.\n",
    "        layer_losses = []\n",
    "    \n",
    "        # For each layer and its corresponding values\n",
    "        # for the content-image.\n",
    "        for value, layer in zip(values, layers):\n",
    "            # These are the values that are calculated\n",
    "            # for this layer in the model when inputting\n",
    "            # the content-image. Wrap it to ensure it\n",
    "            # is a const - although this may be done\n",
    "            # automatically by TensorFlow.\n",
    "            value_const = tf.constant(value)\n",
    "\n",
    "            # The loss-function for this layer is the\n",
    "            # Mean Squared Error between the layer-values\n",
    "            # when inputting the content- and mixed-images.\n",
    "            # Note that the mixed-image is not calculated\n",
    "            # yet, we are merely creating the operations\n",
    "            # for calculating the MSE between those two.\n",
    "            loss = mean_squared_error(layer, value_const)\n",
    "\n",
    "            # Add the loss-function for this layer to the\n",
    "            # list of loss-functions.\n",
    "            layer_losses.append(loss)\n",
    "\n",
    "        # The combined loss for all layers is just the average.\n",
    "        # The loss-functions could be weighted differently for\n",
    "        # each layer. You can try it and see what happens.\n",
    "        total_loss = tf.reduce_mean(layer_losses)\n",
    "        \n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gram_matrix(tensor):\n",
    "    shape = tensor.get_shape()\n",
    "    \n",
    "    # Get the number of feature channels for the input tensor,\n",
    "    # which is assumed to be from a convolutional layer with 4-dim.\n",
    "    num_channels = int(shape[3])\n",
    "\n",
    "    # Reshape the tensor so it is a 2-dim matrix. This essentially\n",
    "    # flattens the contents of each feature-channel.\n",
    "    matrix = tf.reshape(tensor, shape=[-1, num_channels])\n",
    "    \n",
    "    # Calculate the Gram-matrix as the matrix-product of\n",
    "    # the 2-dim matrix with itself. This calculates the\n",
    "    # dot-products of all combinations of the feature-channels.\n",
    "    gram = tf.matmul(tf.transpose(matrix), matrix)\n",
    "\n",
    "    return gram                            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_style_loss(session, model, style_image, layer_ids):\n",
    "    \"\"\"\n",
    "    Create the loss-function for the style-image.\n",
    "    \n",
    "    Parameters:\n",
    "    session: An open TensorFlow session for running the model's graph.\n",
    "    model: The model, e.g. an instance of the VGG16-class.\n",
    "    style_image: Numpy float array with the style-image.\n",
    "    layer_ids: List of integer id's for the layers to use in the model.\n",
    "    \"\"\"\n",
    "\n",
    "    # Create a feed-dict with the style-image.\n",
    "    feed_dict = model.create_feed_dict(image=style_image)\n",
    "\n",
    "    # Get references to the tensors for the given layers.\n",
    "    layers = model.get_layer_tensors(layer_ids)\n",
    "    layerIdCount=len(layer_ids)\n",
    "    print('count of layer ids:',layerIdCount)\n",
    "\n",
    "    # Set the model's graph as the default so we can add\n",
    "    # computational nodes to it. It is not always clear\n",
    "    # when this is necessary in TensorFlow, but if you\n",
    "    # want to re-use this code then it may be necessary.\n",
    "    with model.graph.as_default():\n",
    "        # Construct the TensorFlow-operations for calculating\n",
    "        # the Gram-matrices for each of the layers.\n",
    "        gram_layers = [gram_matrix(layer) for layer in layers]\n",
    "\n",
    "        # Calculate the values of those Gram-matrices when\n",
    "        # feeding the style-image to the model.\n",
    "        values = session.run(gram_layers, feed_dict=feed_dict)\n",
    "\n",
    "        # Initialize an empty list of loss-functions.\n",
    "        layer_losses = []\n",
    "    \n",
    "        # For each Gram-matrix layer and its corresponding values.\n",
    "        for value, gram_layer in zip(values, gram_layers):\n",
    "            # These are the Gram-matrix values that are calculated\n",
    "            # for this layer in the model when inputting the\n",
    "            # style-image. Wrap it to ensure it is a const,\n",
    "            # although this may be done automatically by TensorFlow.\n",
    "            value_const = tf.constant(value)\n",
    "\n",
    "            # The loss-function for this layer is the\n",
    "            # Mean Squared Error between the Gram-matrix values\n",
    "            # for the content- and mixed-images.\n",
    "            # Note that the mixed-image is not calculated\n",
    "            # yet, we are merely creating the operations\n",
    "            # for calculating the MSE between those two.\n",
    "            loss = mean_squared_error(gram_layer, value_const)\n",
    "\n",
    "            # Add the loss-function for this layer to the\n",
    "            # list of loss-functions.\n",
    "            layer_losses.append(loss)\n",
    "\n",
    "        # The combined loss for all layers is just the average.\n",
    "        # The loss-functions could be weighted differently for\n",
    "        # each layer. You can try it and see what happens.\n",
    "        total_loss = tf.reduce_mean(layer_losses)\n",
    "        \n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_denoise_loss(model):\n",
    "    loss = tf.reduce_sum(tf.abs(model.input[:,1:,:,:] - model.input[:,:-1,:,:])) + \\\n",
    "           tf.reduce_sum(tf.abs(model.input[:,:,1:,:] - model.input[:,:,:-1,:]))\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def style_transfer(content_image, style_image,\n",
    "                   content_layer_ids, style_layer_ids,\n",
    "                   weight_content=1.5, weight_style=10.0,\n",
    "                   weight_denoise=0.3,\n",
    "                   num_iterations=120, step_size=10.0):\n",
    "    \"\"\"\n",
    "    Use gradient descent to find an image that minimizes the\n",
    "    loss-functions of the content-layers and style-layers. This\n",
    "    should result in a mixed-image that resembles the contours\n",
    "    of the content-image, and resembles the colours and textures\n",
    "    of the style-image.\n",
    "    \n",
    "    Parameters:\n",
    "    content_image: Numpy 3-dim float-array with the content-image.\n",
    "    style_image: Numpy 3-dim float-array with the style-image.\n",
    "    content_layer_ids: List of integers identifying the content-layers.\n",
    "    style_layer_ids: List of integers identifying the style-layers.\n",
    "    weight_content: Weight for the content-loss-function.\n",
    "    weight_style: Weight for the style-loss-function.\n",
    "    weight_denoise: Weight for the denoising-loss-function.\n",
    "    num_iterations: Number of optimization iterations to perform.\n",
    "    step_size: Step-size for the gradient in each iteration.\n",
    "    \"\"\"\n",
    "\n",
    "    # Create an instance of the VGG16-model. This is done\n",
    "    # in each call of this function, because we will add\n",
    "    # operations to the graph so it can grow very large\n",
    "    # and run out of RAM if we keep using the same instance.\n",
    "    model = vgg16.VGG16()\n",
    "\n",
    "    # Create a TensorFlow-session.\n",
    "    session = tf.InteractiveSession(graph=model.graph)\n",
    "\n",
    "    # Print the names of the content-layers.\n",
    "    print(\"Content layers:\")\n",
    "    print(model.get_layer_names(content_layer_ids))\n",
    "    print('Content Layers:',content_layer_ids)\n",
    "    print()\n",
    "\n",
    "    # Print the names of the style-layers.\n",
    "    print(\"Style layers:\")\n",
    "    print(model.get_layer_names(style_layer_ids))\n",
    "    print('Style Layers:',style_layer_ids)\n",
    "    print()\n",
    "    \n",
    "    #Printing the input paramenter to the function\n",
    "    print('Weight Content:',weight_content)\n",
    "    print('Weight Style:',weight_style)\n",
    "    print('Weight Denoise:',weight_denoise)\n",
    "    print('Number of Iterations:',num_iterations)\n",
    "    print('Step Size:',step_size)\n",
    "    print()\n",
    "\n",
    "    # Create the loss-function for the content-layers and -image.\n",
    "    loss_content = create_content_loss(session=session,\n",
    "                                       model=model,\n",
    "                                       content_image=content_image,\n",
    "                                       layer_ids=content_layer_ids)\n",
    "\n",
    "    # Create the loss-function for the style-layers and -image.\n",
    "    loss_style = create_style_loss(session=session,\n",
    "                                   model=model,\n",
    "                                   style_image=style_image,\n",
    "                                   layer_ids=style_layer_ids)    \n",
    "\n",
    "    # Create the loss-function for the denoising of the mixed-image.\n",
    "    loss_denoise = create_denoise_loss(model)\n",
    "\n",
    "    # Create TensorFlow variables for adjusting the values of\n",
    "    # the loss-functions. This is explained below.\n",
    "    adj_content = tf.Variable(1e-10, name='adj_content')\n",
    "    adj_style = tf.Variable(1e-10, name='adj_style')\n",
    "    adj_denoise = tf.Variable(1e-10, name='adj_denoise')\n",
    "\n",
    "    # Initialize the adjustment values for the loss-functions.\n",
    "    session.run([adj_content.initializer,\n",
    "                 adj_style.initializer,\n",
    "                 adj_denoise.initializer])\n",
    "    \n",
    "\n",
    "    # Create TensorFlow operations for updating the adjustment values.\n",
    "    # These are basically just the reciprocal values of the\n",
    "    # loss-functions, with a small value 1e-10 added to avoid the\n",
    "    # possibility of division by zero.\n",
    "    update_adj_content = adj_content.assign(1.0 / (loss_content + 1e-10))\n",
    "    update_adj_style = adj_style.assign(1.0 / (loss_style + 1e-10))\n",
    "    update_adj_denoise = adj_denoise.assign(1.0 / (loss_denoise + 1e-10))\n",
    "\n",
    "    # This is the weighted loss-function that we will minimize\n",
    "    # below in order to generate the mixed-image.\n",
    "    # Because we multiply the loss-values with their reciprocal\n",
    "    # adjustment values, we can use relative weights for the\n",
    "    # loss-functions that are easier to select, as they are\n",
    "    # independent of the exact choice of style- and content-layers.\n",
    "    loss_combined = weight_content * adj_content * loss_content + \\\n",
    "                    weight_style * adj_style * loss_style + \\\n",
    "                    weight_denoise * adj_denoise * loss_denoise\n",
    "            \n",
    "\n",
    "    # Use TensorFlow to get the mathematical function for the\n",
    "    # gradient of the combined loss-function with regard to\n",
    "    # the input image.\n",
    "    gradient = tf.gradients(loss_combined, model.input)\n",
    "    \n",
    "\n",
    "    # List of tensors that we will run in each optimization iteration.\n",
    "    run_list = [gradient, update_adj_content, update_adj_style, \\\n",
    "                update_adj_denoise]\n",
    "    \n",
    "\n",
    "    # The mixed-image is initialized with random noise.\n",
    "    # It is the same size as the content-image.\n",
    "    mixed_image = np.random.rand(*content_image.shape) + 128\n",
    "\n",
    "    for i in range(num_iterations):\n",
    "        # Create a feed-dict with the mixed-image.\n",
    "        feed_dict = model.create_feed_dict(image=mixed_image)\n",
    "\n",
    "        # Use TensorFlow to calculate the value of the\n",
    "        # gradient, as well as updating the adjustment values.\n",
    "        grad, adj_content_val, adj_style_val, adj_denoise_val \\\n",
    "        = session.run(run_list, feed_dict=feed_dict)\n",
    "        \n",
    "        \n",
    "        # Reduce the dimensionality of the gradient.\n",
    "        grad = np.squeeze(grad)\n",
    "\n",
    "        # Scale the step-size according to the gradient-values.\n",
    "        step_size_scaled = step_size / (np.std(grad) + 1e-8)\n",
    "\n",
    "        # Update the image by following the gradient.\n",
    "        mixed_image -= grad * step_size_scaled\n",
    "\n",
    "        # Ensure the image has valid pixel-values between 0 and 255.\n",
    "        mixed_image = np.clip(mixed_image, 0.0, 255.0)\n",
    "\n",
    "        # Print a little progress-indicator.\n",
    "        print(\". \", end=\"\")\n",
    "\n",
    "        # Display status once every 10 iterations, and the last.\n",
    "        if (i % 10 == 0) or (i == num_iterations - 1):\n",
    "            print()\n",
    "            print(\"Iteration:\", i)\n",
    "\n",
    "            #Print adjustment weights for loss-functions.\n",
    "            msg = \"Weight Adj. for Content: {0:.2e}, Style: {1:.2e}, Denoise: {2:.2e}\"\n",
    "            print(msg.format(adj_content_val, adj_style_val, adj_denoise_val))\n",
    "    \n",
    "            \n",
    "            # Plot the content-, style- and mixed-images.\n",
    "            plot_images(content_image=content_image,\n",
    "                        style_image=style_image,\n",
    "                        mixed_image=mixed_image)\n",
    "            \n",
    "            #Saving the mixed image after every 10 iterations \n",
    "            filename='images/outputs_StyleTransfer/Mixed_Iteration' + str(i) +'.jpg'\n",
    "            print(filename)\n",
    "            save_image(mixed_image, filename)\n",
    "            print()\n",
    "            \n",
    "   \n",
    "    print(\"Final image:\")\n",
    "    plot_image_big(mixed_image)\n",
    "\n",
    "    # Close the TensorFlow session to release its resources.\n",
    "    session.close()\n",
    "    \n",
    "    # Return the mixed-image.\n",
    "    return mixed_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example\n",
    "\n",
    "This example shows how to transfer the style of various images onto a portrait.\n",
    "\n",
    "First we load the content-image which has the overall contours that we want in the mixed-image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "content_filename = 'images/download.jpg'\n",
    "content_image = load_image(content_filename, max_size=None)\n",
    "\n",
    "filenamecontent='images/outputs_StyleTransfer/Content.jpg'\n",
    "print(filenamecontent)\n",
    "save_image(content_image, filenamecontent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we load the style-image which has the colours and textures we want in the mixed-image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "style_filename = 'images/style4.jpg'\n",
    "style_image = load_image(style_filename, max_size=None)\n",
    "\n",
    "filenamestyle='images/outputs_StyleTransfer/Style.jpg'\n",
    "print(filenamestyle)\n",
    "save_image(style_image, filenamestyle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we define a list of integers which identify the layers in the neural network that we want to use for matching the content-image. These are indices into the layers in the neural network. For the VGG16 model, the 5th layer (index 4) seems to work well as the sole content-layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "content_layer_ids = [4,6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we define another list of integers for the style-layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# The VGG16-model has 13 convolutional layers.\n",
    "# This selects all those layers as the style-layers.\n",
    "style_layer_ids = list(range(13))\n",
    "\n",
    "# You can also select a sub-set of the layers, e.g. like this:\n",
    "# style_layer_ids = [1, 2, 3, 4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now perform the style-transfer. This automatically creates the appropriate loss-functions for the style- and content-layers, and \n",
    "\n",
    "then performs a number of optimization iterations. This will gradually create a mixed-image which has similar contours as the content-image, with the colours and textures being similar to the style-image.\n",
    "\n",
    "This can be very slow on a CPU!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "img = style_transfer(content_image=content_image,\n",
    "                     style_image=style_image,\n",
    "                     content_layer_ids=content_layer_ids,\n",
    "                     style_layer_ids=style_layer_ids,\n",
    "                     weight_content=1.5,\n",
    "                     weight_style=10.0,\n",
    "                     weight_denoise=0.3,\n",
    "                     num_iterations=150,\n",
    "                     step_size=10.0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function for printing output image\n",
    "filename='images/outputs_StyleTransfer/Mixed.jpg'\n",
    "save_image(img, filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## License (MIT)\n",
    "\n",
    "Copyright (c) 2016 by [Magnus Erik Hvass Pedersen](http://www.hvass-labs.org/)\n",
    "\n",
    "Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:\n",
    "\n",
    "The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.\n",
    "\n",
    "THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:tf]",
   "language": "python",
   "name": "conda-env-tf-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
